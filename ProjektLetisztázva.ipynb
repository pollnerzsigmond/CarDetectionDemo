{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8482209bb93e5fd0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Define most important functions",
   "id": "ea956a88ac982a41"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-19T19:55:31.904707Z",
     "start_time": "2025-03-19T19:55:31.651586Z"
    }
   },
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def detect_vehicles_yolo_tiny_img(img, weights_path='yolov3-tiny.weights', cfg_path='yolov3-tiny.cfg', class_names_path='coco.names', confidence_threshold=0.5, nms_threshold=0.4):\n",
    "  \n",
    "    try:\n",
    "        # Load the image\n",
    "        height, width, channels = img.shape\n",
    "        # Load class names\n",
    "        with open(class_names_path, 'r') as f:\n",
    "            classes = [line.strip() for line in f.readlines()]\n",
    "        target_classes = ['bus', 'truck', 'motorbike','car']\n",
    "        target_class_indices = []\n",
    "        for class_name in target_classes:\n",
    "            try:\n",
    "                target_class_indices.append(classes.index(class_name))\n",
    "            except ValueError:\n",
    "                print(f\"Warning: '{class_name}' class not found in the class names file.\")\n",
    "        if not target_class_indices:\n",
    "            print(\"Error: None of the target vehicle classes  were found in the class names file.\")\n",
    "            return img, None\n",
    "        # Load the YOLOv3-Tiny network\n",
    "        net = cv2.dnn.readNet(weights_path, cfg_path)\n",
    "        layer_names = net.getLayerNames()\n",
    "        output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "        # Create a blob from the image\n",
    "        blob = cv2.dnn.blobFromImage(img, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "        net.setInput(blob)\n",
    "        outs = net.forward(output_layers)\n",
    "\n",
    "        # Information for drawing bounding boxes\n",
    "        colors = np.random.uniform(0, 255, size=(len(classes), 3))\n",
    "        detections = []\n",
    "\n",
    "        # Process the output layers\n",
    "        for out in outs:\n",
    "            for detection in out:\n",
    "                scores = detection[5:]\n",
    "                class_id = np.argmax(scores)\n",
    "                confidence = scores[class_id]\n",
    "                if confidence > confidence_threshold and class_id in target_class_indices:\n",
    "                    # Object detected\n",
    "                    center_x = int(detection[0] * width)\n",
    "                    center_y = int(detection[1] * height)\n",
    "                    w = int(detection[2] * width)\n",
    "                    h = int(detection[3] * height)\n",
    "\n",
    "                    # Rectangle coordinates\n",
    "                    x = int(center_x - w / 2)\n",
    "                    y = int(center_y - h / 2)\n",
    "\n",
    "                    detections.append([x, y, w, h, confidence, classes[class_id]])\n",
    "\n",
    "        # Apply Non-Maximum Suppression (NMS)\n",
    "        indices = cv2.dnn.NMSBoxes(\n",
    "            [detection[:4] for detection in detections],\n",
    "            [detection[4] for detection in detections],\n",
    "            confidence_threshold,\n",
    "            nms_threshold\n",
    "        )\n",
    "\n",
    "        detected_vehicles = []\n",
    "        if len(indices) > 0:\n",
    "            for i in indices.flatten():\n",
    "                x, y, w, h, confidence, class_name = detections[i]\n",
    "                color = [255,0,0]#colors[classes.index(class_name)]\n",
    "                # Draw the bounding box\n",
    "                \"\"\"                \n",
    "                cv2.rectangle(img, (x, y), (x + w, y + h), color, 2)\n",
    "                # Add the label and confidence\n",
    "                cv2.putText(img, f\"{class_name} {confidence:.2f}\", (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\"\"\"\n",
    "                detected_vehicles.append((x, y, w, h, confidence, class_name))\n",
    "\n",
    "        if detected_vehicles:\n",
    "            return img, detected_vehicles\n",
    "        else:\n",
    "            print(\"No buses, trucks, or motorbikes detected in the image.\")\n",
    "            return img, None\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: One or more required files not found: {e}\")\n",
    "        return None, None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None, None"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T20:02:10.972411Z",
     "start_time": "2025-03-19T20:02:10.959956Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process_detections_with_quadrangle(quad_points, img, detections,overlap_percentage_threshold):\n",
    "    wrongCars=0\n",
    "    if img is None:\n",
    "        return None\n",
    "\n",
    "    if detections is None:\n",
    "        cv2.polylines(img, [np.array(quad_points, np.int32).reshape((-1, 1, 2))], True, (0, 0, 0), 2)\n",
    "        return img\n",
    "\n",
    "    # Draw the quadrangle border\n",
    "    cv2.polylines(img, [np.array(quad_points, np.int32).reshape((-1, 1, 2))], True, (0, 0, 0), 2)\n",
    "\n",
    "    for detection in detections:\n",
    "        x, y, w, h, confidence, class_name = detection\n",
    "        x_min, y_min, x_max, y_max = x, y, x + w, y + h\n",
    "        bbox_points = [(x_min, y_min), (x_max, y_min), (x_max, y_max), (x_min, y_max)]\n",
    "\n",
    "        # Calculate the percentage of the bounding box inside the quadrangle\n",
    "        inside_count = 0\n",
    "        total_points = len(bbox_points)\n",
    "\n",
    "        quad_polygon = np.array(quad_points, np.int32).reshape((1, -1, 2))\n",
    "\n",
    "        for point in bbox_points:\n",
    "            if cv2.pointPolygonTest(quad_polygon, point, False) >= 0:\n",
    "                inside_count += 1\n",
    "\n",
    "        if total_points > 0:\n",
    "            overlap_percentage = (inside_count / total_points) * 100\n",
    "        else:\n",
    "            overlap_percentage = 0\n",
    "\n",
    "        color = (255, 0, 0)  # Default blue color\n",
    "        if overlap_percentage >= overlap_percentage_threshold*100:\n",
    "            color = (0, 0, 255)  # Red color\n",
    "            wrongCars+=1\n",
    "            \n",
    "\n",
    "        # Draw the bounding box\n",
    "        cv2.rectangle(img, (x, y), (x + w, y + h), color, 2)\n",
    "        # Add the label and confidence\n",
    "        cv2.putText(img, f\"{class_name} {confidence:.2f}\", (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "    return img,wrongCars"
   ],
   "id": "3df5a4c2a22e452f",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "accf03e06a19f243"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Let's play with them",
   "id": "7c05bb8777b98d72"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "get the datafiles for neural network",
   "id": "af634f0c13cd510"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T19:57:46.830981Z",
     "start_time": "2025-03-19T19:57:46.826497Z"
    }
   },
   "cell_type": "code",
   "source": [
    "weights_file = \"/home/zsicomp/Downloads/darknet-test-master/yolov3-tiny.weights\"  # Path to your weights file\n",
    "config_file = \"/home/zsicomp/Downloads/darknet-test-master/yolov3-tiny.cfg\"     # Path to your configuration file\n",
    "class_names_file = \"/home/zsicomp/Downloads/darknet-test-master/coco.names\"   # Path to the class names file"
   ],
   "id": "b803b75715febe82",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "put our image file path here:",
   "id": "e12ac3eee351f7a1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T20:09:56.757562Z",
     "start_time": "2025-03-19T20:09:56.752382Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#image_file = \"/home/zsicomp/Downloads/20250304_131409.jpg\"  #My photo\n",
    "#image_file =\"/home/zsicomp/Downloads/ÜllőiÚt2024.png\" #No bad car on it rossz auto rajta\n",
    "image_file=\"/home/zsicomp/Downloads/BiciklisfutarAutotKerul.jpg\"\n",
    "#image_file = \"/home/zsicomp/Downloads/UlloiBringasavParkolas.png\"  # Replace with the path to your image\n",
    "#image_file = \"/home/zsicomp/Downloads/UlloiUtParkolas2.png\" "
   ],
   "id": "99bd106c0a6500a0",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T20:09:57.178876Z",
     "start_time": "2025-03-19T20:09:57.035956Z"
    }
   },
   "cell_type": "code",
   "source": "image = cv2.imread(image_file) # load the chosen image",
   "id": "92e1cfa77ad8dc1b",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Resize the image if it is too large for better handling (for computer vision we will use anyway images around 400 px)",
   "id": "ad4080aa94401ff7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T20:10:00.108071Z",
     "start_time": "2025-03-19T20:10:00.066203Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#reshape image if it is too large\n",
    "print(image.shape,\"Original Image size\")\n",
    "\n",
    "if image.shape[0]>700 or image.shape[1]>700:\n",
    "    if image.shape[0] < image.shape[1]:\n",
    "        scale_factor= 700/image.shape[1]\n",
    "    else:\n",
    "        scale_factor= 700/image.shape[0]\n",
    "    width = int(image.shape[1] * scale_factor)\n",
    "    height = int(image.shape[0] * scale_factor)\n",
    "    dim = (width, height)\n",
    "    img = cv2.resize(image[:,:,:], dim, interpolation=cv2.INTER_AREA)\n",
    "else:\n",
    "    img=image\n",
    "    \n",
    "print(img.shape,\"Resized image\")\n",
    "# Resize the image\n",
    "\n",
    "#print(resized_img.shape)"
   ],
   "id": "43ac9d3942edcdc8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3024, 4032, 3) Original Image size\n",
      "(525, 700, 3) Resized image\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Select the area within the cars are in wrong place. Click around the area. After each click you will see a circle and a number where you clicked. you can slect only one patch, and make it **convex**;\n",
    "## After clicking exit with any button"
   ],
   "id": "6ca76672b8f7e983"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "## Select the",
   "id": "d9b0117ac6af22cb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T20:10:09.210221Z",
     "start_time": "2025-03-19T20:10:02.028087Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#find the points within them we think cars must not park.\n",
    "# click on points in an order, when you connect them get a good looking rectangle\n",
    "PointPairs=[]\n",
    "imgForPints=img.copy()\n",
    "def draw_circle(event, x, y, flags, param):\n",
    "    \n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        cv2.circle(img=imgForPints, center=(x,y), radius=10, color=(0,255,0), thickness=5)\n",
    "        PointPairs.append((x,y))\n",
    "        cv2.putText(imgForPints, str(len(PointPairs)),(x,y), cv2.FONT_HERSHEY_SIMPLEX, 0.8, [0,0,240], 2) # we will nummber the clicks\n",
    "\n",
    "# conect drawing function to image window\n",
    "cv2.namedWindow(winname='image')\n",
    "cv2.setMouseCallback('image', draw_circle)\n",
    "\n",
    "# showing image\n",
    "\n",
    "while True:\n",
    "    \n",
    "    cv2.imshow('image', imgForPints)\n",
    "    \n",
    "    if cv2.waitKey(20) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ],
   "id": "8121189c4d4128dc",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![image info](./RosszTartomanyKijelolese.png)",
   "id": "a4f076246f835f8d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Do the detection:",
   "id": "d65352f929b78acf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T20:11:14.107201Z",
     "start_time": "2025-03-19T20:11:13.860024Z"
    }
   },
   "cell_type": "code",
   "source": [
    "detected_image, vehicle_detections = detect_vehicles_yolo_tiny_img(\n",
    "    img,\n",
    "    weights_path=weights_file,\n",
    "    cfg_path=config_file,\n",
    "    class_names_path=class_names_file,\n",
    "    confidence_threshold=0.2,\n",
    "    nms_threshold=0.3\n",
    ")# make the image detection, with relatively low confidence values"
   ],
   "id": "99a183e4e07075e9",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Show recognised image\n",
    "* Around the forbidden are you will have a black line\n",
    "* \"Cars\" in wrong place get red rectangle around them\n",
    "* \"Cars\" detected on other places will get blue rectangles"
   ],
   "id": "4037fe7c9718cac8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T20:11:32.998727Z",
     "start_time": "2025-03-19T20:11:16.545287Z"
    }
   },
   "cell_type": "code",
   "source": [
    "EpicImage4,wrongCars=process_detections_with_quadrangle(PointPairs, img, vehicle_detections,0.4)\n",
    "cv2.imshow(\"Vehicle Detection\", EpicImage4)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "id": "5b2936a8b14fb6ad",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![image info](./FinallyCarIsInWrongPlace.png)",
   "id": "9b2e7babdf719"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T20:16:02.108781Z",
     "start_time": "2025-03-19T20:16:02.090500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if wrongCars==0:\n",
    "    print(\"There are only good drivers, or computer vision is not working well\")\n",
    "else:\n",
    "    print(\"Number of cars in wrong place are:\", wrongCars)"
   ],
   "id": "5eb0541a16c070ce",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cars in wrong place are: 1\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "11b93764798a9696"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Later I plan to recognise car color and numberplate, thereby I can tell the car owner on a loud speaker to move the car. And with number plate and car color maybe the message will be more personal",
   "id": "ca5458f9a4be976"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "c74b6e788ba1c2dc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "891ec1ba5a88bb79"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
